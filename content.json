[{"title":"OpenCV之CascadeClassifier(一)","date":"2017-02-20T06:23:58.000Z","path":"2017/02/20/OpenCV之CascadeClassifier-一/","text":"","tags":[{"name":"研习","slug":"研习","permalink":"http://yoursite.com/tags/研习/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/tags/OpenCV/"}]},{"title":"OpenCV之Mat(一)","date":"2017-02-20T05:43:01.000Z","path":"2017/02/20/OpenCV之Mat-一/","text":"废话内容，写在前面： Mat是个什么玩意? 2015年下半年我在祈飞科技做视觉软件工程师的时候，一边看C++的入门内容，一边敲一点点和工作有关的代码。有一天飞哥和勇哥终于按耐不住觉得我总是测试光学打光做电子元器件可能就真的要废了，于是飞哥让我用Visual Studio把一张图片用窗口展示出来，然后对图片进行二值化处理，提取特征值。 我印象特别深刻，方法函数里面涉及到了好多Mat，而我记得Mat是跟图像关系很大的一个类，也没时间去深究，反到在我心里留下很深刻的印象，现如今开始动OpenCV第一个要理解的东西就是Mat，在这里我想我把研读的关于Mat类是什么，来记录一下。 OpenCV官方文档是这样界定Mat的：基本的图像容器。 处理一张图片为何要用到图像的容器这种定义的概念？没有《图像处理技术》基础知识的人可能不太能懂图像为何需要一个基本的图像容器去处理。我记得我本科上《图像处理技术》的时候，虽然也不听课，但是偶尔睡醒犯困或者老师提问的时候，我会因为一个激灵听到看到的内容，反而现在印象深刻，图像是很多像素点构成，每个像素点有具体的像素值(0~255)，一张二维平面上的图片，它上面所有的点平面坐标位置,有点像《线性代数》里的矩阵，处理一张图片就是处理图片上所包含的像素值的信息，所以图片的处理，就可以转换成矩阵运算。 正如OpenCV官方文档上说到的：如何获取并存储这些像素值由我们的需求而定，最终在计算机世界里所有图像都可以简化为数值矩以及矩阵信息。作为一个计算机视觉库， OpenCV 其主要目的就是通过处理和操作这些信息，来获取更高级的信息。因此，OpenCV如何存储并操作图像是你首先要学习的。 Mat的发展情况： 在2001年刚刚出现的时候，OpenCV基于C语言接口而建。为了在内存（memory）中存放图像，当时采用名为IplImage的C语言结构体，时至今日这仍出现在大多数的旧版教程和教学材料。但这种方法必须接受C语言所有的不足，这其中最大的不足要数手动内存管理，其依据是用户要为开辟和销毁内存负责。虽然对于小型的程序来说手动管理内存不是问题，但一旦代码开始变得越来越庞大，你需要越来越多地纠缠于这个问题，而不是着力解决你的开发目标。 幸运的是，C++出现了，并且带来类的概念，这给用户带来另外一个选择：自动的内存管理（不严谨地说）。这是一个好消息，如果C++完全兼容C的话，这个变化不会带来兼容性问题。为此，OpenCV在2.0版本中引入了一个新的C++接口，利用自动内存管理给出了解决问题的新方法。使用这个方法，你不需要纠结在管理内存上，而且你的代码会变得简洁（少写多得）。但C++接口唯一的不足是当前许多嵌入式开发系统只支持C语言。所以，当目标不是这种开发平台时，没有必要使用旧方法（除非你是自找麻烦的受虐狂码农）。 关于 Mat ，首先要知道的是你不必再手动地（1）为其开辟空间（2）在不需要时立即将空间释放。但手动地做还是可以的：大多数OpenCV函数仍会手动地为输出数据开辟空间。当传递一个已经存在的 Mat 对象时，开辟好的矩阵空间会被重用。也就是说，我们每次都使用大小正好的内存来完成任务。 基本上讲 Mat 是一个类，由两个数据部分组成：矩阵头（包含矩阵尺寸，存储方法，存储地址等信息）和一个指向存储所有像素值的矩阵（根据所选存储方法的不同矩阵可以是不同的维数）的指针。矩阵头的尺寸是常数值，但矩阵本身的尺寸会依图像的不同而不同，通常比矩阵头的尺寸大数个数量级。因此，当在程序中传递图像并创建拷贝时，大的开销是由矩阵造成的，而不是信息头。OpenCV是一个图像处理库，囊括了大量的图像处理函数，为了解决问题通常要使用库中的多个函数，因此在函数中传递图像是家常便饭。同时不要忘了我们正在讨论的是计算量很大的图像处理算法，因此，除非万不得已，我们不应该拷贝 大 的图像，因为这会降低程序速度。 为了搞定这个问题，OpenCV使用引用计数机制。其思路是让每个 Mat 对象有自己的信息头，但共享同一个矩阵。这通过让矩阵指针指向同一地址而实现。而拷贝构造函数则 只拷贝信息头和矩阵指针 ，而不拷贝矩阵。 关于 Mat 内存管理的问题： 如果矩阵属于多个 Mat 对象，那么当不再需要它时谁来负责清理？简单的回答是：最后一个使用它的对象。通过引用计数机制来实现。无论什么时候有人拷贝了一个 Mat 对象的信息头，都会增加矩阵的引用次数；反之当一个头被释放之后，这个计数被减一；当计数值为零，矩阵会被清理。但某些时候你仍会想拷贝矩阵本身(不只是信息头和矩阵指针)，这时可以使用函数 clone() 或者 copyTo() 。 1.OpenCV函数中输出图像的内存分配是自动完成的（如果不特别指定的话）。 2.使用OpenCV的C++接口时不需要考虑内存释放问题。 3.赋值运算符和拷贝构造函数（ ctor ）只拷贝信息头。 4.使用函数 clone() 或者 copyTo() 来拷贝一副图像的矩阵。 以上是对图像以及 Mat类发展，以及OpenCV在处理图像时的内存管理的一个简单的了解。 接下来要了解一下OpenCV是如何存储图像的： 这里讲述如何存储像素值。需要指定颜色空间和数据类型。颜色空间是指对一个给定的颜色，如何组合颜色元素以对其编码。最简单的颜色空间要属灰度级空间，只处理黑色和白色，对它们进行组合可以产生不同程度的灰色。 对于 彩色 方式则有更多种类的颜色空间，但不论哪种方式都是把颜色分成三个或者四个基元素，通过组合基元素可以产生所有的颜色。RGB颜色空间是最常用的一种颜色空间，这归功于它也是人眼内部构成颜色的方式。它的基色是红色、绿色和蓝色，有时为了表示透明颜色也会加入第四个元素 alpha (A)。 有很多的颜色系统，各有自身优势： 1.RGB是最常见的，这是因为人眼采用相似的工作机制，它也被显示设备所采用。 2.HSV和HLS把颜色分解成色调、饱和度和亮度/明度。这是描述颜色更自然的方式，比如可以通过抛弃最后一个元素，使算法对输入图像的光照条件不敏感。 3.YCrCb在JPEG图像格式中广泛使用。 4.CIE L a b *是一种在感知上均匀的颜色空间，它适合用来度量两个颜色之间的距离。 每个组成元素都有其自己的定义域，取决于其数据类型。如何存储一个元素决定了我们在其定义域上能够控制的精度。最小的数据类型是 char ，占一个字节或者8位，可以是有符号型（0到255之间）或无符号型（-127到+127之间）。尽管使用三个 char 型元素已经可以表示1600万种可能的颜色（使用RGB颜色空间），但若使用float（4字节，32位）或double（8字节，64位）则能给出更加精细的颜色分辨能力。但同时也要切记增加元素的尺寸也会增加了图像所占的内存空间。 关于Mat类的创建，具体的代码和内容可以查阅OpenCV中文网里的相关入门教学，当然还要具备一点点基础的C++入门知识。 待续以后会更新相关内容，等我把C++入门摸一下。","tags":[{"name":"研习","slug":"研习","permalink":"http://yoursite.com/tags/研习/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/tags/OpenCV/"}]},{"title":"一个iOS开发者在做人脸识别(一)","date":"2017-02-20T02:01:22.000Z","path":"2017/02/20/一个iOS开发者在做人脸识别-一/","text":"废话内容，写在前面: 2016年上半年在上海面试的时候。徐汇区有一家做社交的互联网公司开始打算做人脸识别，由此我了解了深圳脸萌科技的FaceU这款超级激萌的App。很有意思的是徐汇区那家社交公司面试我的时候跟我说的很明确：你做一个类似FaceU的demo给我，我就给你发Offer。有时候我在想一份工作好简单啊，只要你会做人脸识别添加贴纸贴片，一碗饭就来了。 回去之后，我对比了iOS框架自带的人脸识别框架识别的精度不够高，侧脸极其难识别，我只好放弃转而奔向科大讯飞人脸识别的框架去做。 那一个礼拜的时间里，我看科大讯飞的人脸识别SDK和官方Demo，在做识别的过程中想加贴片装饰品的时候，遇到了二个代理方法的冲突，导致某个识别状态始终无法修改。所以那次的demo最终是没有做出来。 时隔快一年，我想人脸识别功能我该动一动了，恰好个人技术博客刚开张，也应该来一点技术干货。同时不一样的是，这次我也不打算用科大讯飞的框架，我想从OpenCV的开源库着手，多多少少还可以学点C++的函数也还不错。 由此我想把研究人脸识别的过程记录下来。所以这个系列是一个不懂C++的iOS开发小白的学习过程。 本系列文章，所有测试内容以及demo的环境如下： 1）Xcode Version 8.2.1 2）OpenCV for iOS 3.2.0 准备工作： 1）先去OpenCV官网下载最新的OpenCV For iOS的视觉库。 2）Xcode创建一个新的项目，把下载的OpenCV库导入工程，并在工程的Building phase里面添加opencv2.framework。 如果对OpenCV有所了解的会知道，OpenCV的代码是基于C++编写的。因此，想要在Xcode项目中运行C++代码，你需要把文件名后缀名由.m改成.mm即可（当然最好把OpenCV的功能函数写一层OC的API封装，这样可能会比较安全，也会少很多不必要的错误麻烦，也更符合开发需求。）。 注意：OpenCV 声明了命名空间 cv，因此 OpenCV 的类的前面会有个 cv:: 前缀，就像 cv::Mat、 cv::Algorithm 等等。你也可以在 .mm 文件中使用 using namespace cv 来避免在一堆类名前使用 cv:: 前缀。 但是，在某些类名前你必须使用命名空间前缀，比如 cv::Rect 和 cv::Point，因为它们会跟定义在 MacTypes.h 中的 Rect 和 Point 相冲突。尽管这只是个人偏好问题，个人偏向在任何地方都使用 cv:: 以保持一致性。 C++ 命名空间namespace的作用和使用: 命名空间是ANSIC++引入的可以由用户命名的作用域，用来处理程序中 常见的同名冲突。其作用就是规定该文件中使用的标准库函数都是在标准命名空间std中定义的。通常来说，在C++中，命名空间（namespace）的目的是为了防止名字冲突。每个命名空间是一个作用域，在所有命名空间之外，还存在一个全局命名空间（global namespace），全局命名空间以隐式的方式声明，它并没有名字。在命名空间机制中，原来的全局变量，就是位于全局命名空间中（可以用::member的形式表示）。 在C语言中定义了3个层次的作用域，即文件(编译单元)、函数和复合语句。C++在C的基础上又引入了类作用域，类是出现在文件内的。在不同的作用域中可以定义相同名字的变量，互不于扰，系统能够区别它们。 在导入opencv2.framework之后，把你需要加入OpenCV代码的文件的.m文件后缀由.m改成.mm 引入头文件 #import &lt;opencv2/opencv.hpp&gt; #import &lt;opencv2/imgproc/types_c.h&gt; #import &lt;opencv2/imgcodecs/ios.h&gt; 编译运行。 PS:我编译的时候，有二个报错。经过查阅资料做了具体的修改调整之后可以正常运行，分别是OpenCV库的 blenders.hpp 文件 enum { NO, FEATHER, MULTI_BAND }; 修改成： enum { NO_EXPOSURE_COMPENSATOR, FEATHER, MULTI_BAND }; 和exposure_compensate.hpp文件 enum { NO, GAIN, GAIN_BLOCKS }; 修改成： enum { NO_EXPOSURE_COMPENSATOR, GAIN, GAIN_BLOCKS }; 先来试试OpenCV的入门内容，把一张彩色图片变成灰色的 在控制器的.mm文件中引入Mat类 @interface ViewController () { cv::Mat cvImage; } @end 关于Mat类:详见另一篇Blog：OpenCV之Mat(一) 图像处理的代码块如下： if(!cvImage.empty()){ cv::Mat gray; // 将图像转换为灰度显示 cv::cvtColor(cvImage,gray,CV_RGB2GRAY); // 应用高斯滤波器去除小的边缘 cv::GaussianBlur(gray, gray, cv::Size(5,5), 1.2,1.2); // 计算与画布边缘 cv::Mat edges; cv::Canny(gray, edges, 0, 50); // 使用白色填充 cvImage.setTo(cv::Scalar::all(225)); // 修改边缘颜色 cvImage.setTo(cv::Scalar(0,128,255,255),edges); // 将Mat转换为Xcode的UIImageView显示 self.testImgView1.image = MatToUIImage(cvImage); } 如果你和我一样运行Xcode之后能得到下图的处理后的照片内容的话，图像的灰度显示算是完成了。 也就是说OpenCV的第一个代码块已经完成了。 如果还有兴趣的话，可以接着玩玩—–人脸识别 现在在你的.mm控制器里引入CascadeClassifier类 @interface ViewController () { cv::CascadeClassifier faceDetector; } @end 关于CascadeClassifier类的调研:详见另一篇Blog：OpenCV之CascadeClassifier(一) 人脸识别核心代码如下: NSString *cascadePath = [[NSBundle mainBundle] pathForResource:@&quot;haarcascade_frontalface_alt&quot; ofType:@&quot;xml&quot;]; faceDetector.load([cascadePath UTF8String]); cv::Mat faceImage; UIImageToMat(image, faceImage); // 转为灰度 cv::Mat gray; cvtColor(faceImage, gray, CV_BGR2GRAY); // 检测人脸并储存 std::vector&lt;cv::Rect&gt;faces; faceDetector.detectMultiScale(gray, faces,1.1,2,0|CV_HAAR_SCALE_IMAGE,cv::Size(30,30)); // 在每个人脸上画一个红色四方形 for(unsigned int i= 0;i &lt; faces.size();i++) { const cv::Rect&amp; face = faces[i]; cv::Point tl(face.x,face.y); cv::Point br = tl + cv::Point(face.width,face.height); // 四方形的画法 cv::Scalar magenta = cv::Scalar(255, 0, 255); cv::rectangle(faceImage, tl, br, magenta, 4, 8, 0); } self.testImgView2.image = MatToUIImage(faceImage); 如果你得到了下图样式(imageView重新布局了)，第三个相框里的每个人脸上都有正方形的框，表示已经找到了人脸位置（haarcascade_frontalface_alt.xml该文件是通过训练获得的数据文件，作为资源训练模型）。 到此时，人脸识别算是初步完成。 demo的git链接：","tags":[{"name":"研习","slug":"研习","permalink":"http://yoursite.com/tags/研习/"},{"name":"C++","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://yoursite.com/tags/OpenCV/"},{"name":"人脸识别","slug":"人脸识别","permalink":"http://yoursite.com/tags/人脸识别/"}]},{"title":"要尝试逃离上广深了么？","date":"2017-02-19T13:53:20.000Z","path":"2017/02/19/要尝试逃离上广深了么？/","text":"2017年2月19日了，这天比预期的时间晚来了30天，30天前我告诉自己，要弄一个个人站点，不管这个站点的Theme是从哪个大牛手里偷的，都要先用着。 本来在现有的Hexo成熟的框架条件下，个人博客最多20分钟就可以弄好，但是我却花了比我预期多的多的时间。这些事件都耗费在哪了？耗费在不够专注：上班修改优化项目零碎的时间里，Hexo安装错误，一波接着一波的安装卸载，GitHub Pages删了又重新添加，全是无用之功。 2月17日的4个面试还毫无消息，Cisco上海的技术面问了我很多基础的东西，我模凌两可含含糊糊的回答，26分钟就从大厦出来，我想也是应该的，从没有如此草率的面试，毫无准备，必然不会受到待见。可是为啥我要把自己的实力不足归咎于准备不充分呢？没有什么台阶要给自己下的。自己无能是原罪。那天下午在浦东张江高科，那个逆向开发公司的技术面和我聊了20多分钟，问我最近研究什么，问我最近开发上的难点有哪些，我一五一十的说着，后来问我：你会给iPhone越狱嘛？我说我没做过的时候他合起了他的Mac，我想这已经终结聊天了，我也本想抱着试试的态度来的，底层汇编我又没那个能力去做，不被待见显而易见，但是第一次面试和别人聊天不在同一个频道的时候，让我感觉空气里到处弥漫着尴尬。 之后我坐在老甲公司楼下的台阶上吹冷风，手机没电我打开Mac给它喂奶，我好气的，好不容易编了个很奇葩的理由请假面试，却被自己白白糟蹋一天。我告诉自己都会好的，就像春天来了，柳絮会飘，秋天过来，柿子会熟。少年你不能太着急的。我安慰自己啊，别急，你可以的，这个世界本来就给你留好了位置，你还没遇到最好的自己。可是没用的啊，那天风好大，鼻子好酸，眼角都湿得一直没干，自我安慰的那些屁话肯定没有老甲带我去吃那顿热气腾腾的麻辣烫管用，张江高科消费好贵的，0.8公斤的料，48块钱，温饱了那天我饥饿的灵魂。 大概是太过于急功近利。技术需要沉淀的，一点点去学，代码要慢慢的打磨，一行行的敲，这个膨胀的社会却不给年轻人那么多时间去沉淀，膨胀的自己也不给自己那么多机会去尝试。 2016年的每一天我都掰开着用，这一年我都没时间去做噩梦，忙得让我很少在半夜里会醒来，往往都是半夜才睡。那个时候我告诉自己，你要努力，你现在多累些，当下就少求别人一点。下半年项目加班加点，干过40多个小时没合眼，我也不曾抱怨，因为毕竟自己菜，只能用时间来弥补，我把别人喝咖啡的时候都用来写项目了。我庆幸我足够的年轻，年轻到身体严重负荷的时候，仅仅只是胸口有点痛而已。一觉醒来，代码还可以撸的飞起。 TinyTian说代码是我大老婆，她是小三，满是哀怨的时候我只能咧开嘴笑，的确我欠她太多的时间。有时候我在想，幸福的日子就是有一个人成了你这一生唯一的软肋，遇事再也不莽撞，即使丢掉激情你也不会觉得后悔。好寡淡的时光啊，可就是这么心安理得的欢喜。 有时候很多事情来的莫名其妙，中午在地铁上打瞌睡打盹点开Boss聊了一个，立马要了简历，后来才知道那是合肥的一家美容公司。紧接着下午就视讯通话面试过了，傍晚给我发了Offer，在合肥，试用期税前9K，转正11K，可是我不知道为啥高兴不起来呢，是我过于贪恋一线城市夜晚的霓虹灯么，总是在心里告诉自己一线城市机会多，技术提升快。可是迟早终究要回到那个城市的，为何不早做打算，非要漫无目的的幻想么？ 现在这个机会就摆在我的面前了，我却踌躇满志，迈不开步子。可这又算什么呢？反正我的时间又不值钱，可以大把的浪费大把的挥霍。 年轻就是要这样的吧，都不确定，都在准备呢，试试又不是一个坏事，何况又不是最惨的时候。 毕竟还有那么多希望。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"},{"name":"Hexo + Github Pages","slug":"Hexo-Github-Pages","permalink":"http://yoursite.com/tags/Hexo-Github-Pages/"}]}]